# Streamlit ì•± ì‹¤í–‰í•˜ê¸°
# í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
# streamlit run advanced_chatbot_gpt.py

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import streamlit as st
from openai import OpenAI

# ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë‚˜ì˜ AI ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide"  # í™”ë©´ì„ ë„“ê²Œ ì‚¬ìš©
)

# ì œëª© í‘œì‹œ
st.title("ğŸ¤– ë‚˜ì˜ AI ì±—ë´‡ Pro")
st.write("ë” ë˜‘ë˜‘í•´ì§„ ì±—ë´‡! ì•„ë˜ ì¶”ì²œ ì§ˆë¬¸ì„ í´ë¦­í•˜ê±°ë‚˜ ì§ì ‘ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    # API í‚¤ ì…ë ¥
    api_key = st.text_input("OpenAI API í‚¤", type="password")

    st.divider()  # êµ¬ë¶„ì„ 

    # AI ëª¨ë¸ ì„ íƒ
    st.subheader("ğŸ¯ AI ëª¨ë¸ ì„ íƒ")
    model_option = st.selectbox(
        "ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”",
        ["gpt-5-nano", "gpt-4o-mini"],
        help="gpt-5-nanoëŠ” ì €ë ´í•œ ìµœì‹  ëª¨ë¸ì´ê³ , gpt-4o-miniëŠ” ì†Œí˜• ê³ ì„±ëŠ¥ ëª¨ë¸ì…ë‹ˆë‹¤."
    )
    # gpt-5-nanoëŠ” temperature ì„¤ì •ì„ í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— í•´ë‹¹ ë‚´ìš©ì€ ìƒëµí•©ë‹ˆë‹¤.

    st.divider()

    # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
    st.subheader("ğŸ’¾ ëŒ€í™” ê´€ë¦¬")
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ì—­ ì§€ìš°ê¸°", use_container_width=True):
        st.session_state.messages = []
        st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨

    # ëŒ€í™” ê°œìˆ˜ í‘œì‹œ
    message_count = len(st.session_state.messages)
    st.info(f"í˜„ì¬ ëŒ€í™” ê°œìˆ˜: {message_count}ê°œ")

# API í‚¤ í™•ì¸
if not api_key:
    st.warning("âš ï¸ ì™¼ìª½ ì‚¬ì´ë“œë°”ì— API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = OpenAI(api_key=api_key)

# ì¶”ì²œ ì§ˆë¬¸ ë²„íŠ¼
st.subheader("ğŸ’¡ ì¶”ì²œ ì§ˆë¬¸")
col1, col2, col3, col4 = st.columns(4)

# ì¶”ì²œ ì§ˆë¬¸ ëª©ë¡
suggested_questions = [
    "ì¸ê³µì§€ëŠ¥ì´ ë­”ê°€ìš”?",
    "íŒŒì´ì¬ìœ¼ë¡œ í•  ìˆ˜ ìˆëŠ” ê²ƒì€?",
    "ê±´ê°•í•œ ì•„ì¹¨ ì‹ì‚¬ ì¶”ì²œí•´ì¤˜",
    "ì¬ë¯¸ìˆëŠ” ë†ë‹´ í•˜ë‚˜ í•´ì¤˜"
]

# ê° ì—´ì— ë²„íŠ¼ ë°°ì¹˜
with col1:
    if st.button(suggested_questions[0], use_container_width=True):
        st.session_state.selected_question = suggested_questions[0]

with col2:
    if st.button(suggested_questions[1], use_container_width=True):
        st.session_state.selected_question = suggested_questions[1]

with col3:
    if st.button(suggested_questions[2], use_container_width=True):
        st.session_state.selected_question = suggested_questions[2]

with col4:
    if st.button(suggested_questions[3], use_container_width=True):
        st.session_state.selected_question = suggested_questions[3]

st.divider()

# ëŒ€í™” ë‚´ìš© í‘œì‹œ
# ì´ì „ ëŒ€í™” ë‚´ìš© í™”ë©´ì— í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
# ì¶”ì²œ ì§ˆë¬¸ ë²„íŠ¼ì„ í´ë¦­í–ˆì„ ë•Œ
if "selected_question" in st.session_state:
    user_input = st.session_state.selected_question
    del st.session_state.selected_question  # ì‚¬ìš© í›„ ì‚­ì œ
else:
    # ì¼ë°˜ ì…ë ¥
    user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")

# ì‚¬ìš©ìê°€ ë©”ì‹œì§€ë¥¼ ì…ë ¥í–ˆì„ ë•Œ
if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": user_input})

    # ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ
    with st.chat_message("user"):
        st.write(user_input)

    # AI ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
    with st.chat_message("assistant"):
        message_placeholder = st.empty()

        # ìŠ¤í”¼ë„ˆ í‘œì‹œ (ë¡œë”© ì¤‘)
        with st.spinner("ìƒê° ì¤‘..."):
            try:
                # GPT API í˜¸ì¶œ
                response = client.chat.completions.create(
                    model=model_option,  # ì‚¬ìš©í•  AI ëª¨ë¸
                    messages=st.session_state.messages,  # ì „ì²´ ëŒ€í™” ë‚´ì—­ ì „ì†¡
                    stream=True  # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì‘ë‹µ ë°›ê¸° (íƒ€ì´í•‘ íš¨ê³¼)
                )

                # AI ì‘ë‹µì„ ì¡°ê¸ˆì”© ë°›ì•„ì„œ í™”ë©´ì— í‘œì‹œ
                full_response = ""
                for chunk in response:
                    if chunk.choices[0].delta.content is not None:
                        full_response += chunk.choices[0].delta.content
                        message_placeholder.write(full_response + "â–Œ")

                # ìµœì¢… ì‘ë‹µ í‘œì‹œ
                message_placeholder.write(full_response)

            except Exception as e:
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë©”ì‹œì§€ í‘œì‹œ
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                full_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                message_placeholder.write(full_response)

    # AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    st.session_state.messages.append({"role": "assistant", "content": full_response})

    # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ (ì¶”ì²œ ì§ˆë¬¸ ë²„íŠ¼ ë•Œë¬¸)
    st.rerun()

# í•˜ë‹¨ ì•ˆë‚´ ë©”ì‹œì§€
if len(st.session_state.messages) == 0:
    st.info("ğŸ‘† ìœ„ì˜ ì¶”ì²œ ì§ˆë¬¸ì„ í´ë¦­í•˜ê±°ë‚˜, ì•„ë˜ì— ì§ì ‘ ì§ˆë¬¸ì„ ì…ë ¥í•´ë³´ì„¸ìš”!")