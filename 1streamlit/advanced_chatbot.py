# Streamlit ì•± ì‹¤í–‰í•˜ê¸°
# í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
# streamlit run advanced_chatbot.py

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import streamlit as st
import google.generativeai as genai

# ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë‚˜ì˜ AI ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ì œëª© í‘œì‹œ
st.title("ğŸ¤– ë‚˜ì˜ AI ì±—ë´‡ Pro")
st.write("ë” ë˜‘ë˜‘í•´ì§„ ì±—ë´‡! ì•„ë˜ ì¶”ì²œ ì§ˆë¬¸ì„ í´ë¦­í•˜ê±°ë‚˜ ì§ì ‘ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    # API í‚¤ ì…ë ¥
    api_key = st.text_input("Gemini API í‚¤", type="password")

    st.divider()

    # AI ëª¨ë¸ ì„ íƒ
    st.subheader("ğŸ¯ AI ëª¨ë¸ ì„ íƒ")
    model_option = st.selectbox(
        "ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”",
        ["gemini-2.5-flash", "gemini-2.5-pro"],
        help="flashëŠ” ë¹ ë¥´ê³ , proëŠ” ë” ì •í™•í•©ë‹ˆë‹¤."
    )

    # ì˜¨ë„ ì„¤ì • (ì°½ì˜ì„± ì¡°ì ˆ)
    st.subheader("ğŸŒ¡ï¸ ì°½ì˜ì„± ì¡°ì ˆ")
    temperature = st.slider(
        "Temperature",
        min_value=0.0,
        max_value=2.0,
        value=0.7,
        step=0.1,
        help="ë†’ì„ìˆ˜ë¡ ë” ì°½ì˜ì ì´ì§€ë§Œ ëœ ì •í™•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
    )

    st.divider()

    # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
    st.subheader("ğŸ’¾ ëŒ€í™” ê´€ë¦¬")
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ì—­ ì§€ìš°ê¸°", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    # ëŒ€í™” ê°œìˆ˜ í‘œì‹œ
    message_count = len(st.session_state.messages)
    st.info(f"í˜„ì¬ ëŒ€í™” ê°œìˆ˜: {message_count}ê°œ")

# API í‚¤ í™•ì¸
if not api_key:
    st.warning("âš ï¸ ì™¼ìª½ ì‚¬ì´ë“œë°”ì— API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

# Gemini í´ë¼ì´ì–¸íŠ¸ ìƒì„±
genai.configure(api_key=api_key)

# ì¶”ì²œ ì§ˆë¬¸ ë²„íŠ¼
st.subheader("ğŸ’¡ ì¶”ì²œ ì§ˆë¬¸")
col1, col2, col3, col4 = st.columns(4)

# ì¶”ì²œ ì§ˆë¬¸ ëª©ë¡
suggested_questions = [
    "ì¸ê³µì§€ëŠ¥ì´ ë­”ê°€ìš”?",
    "íŒŒì´ì¬ìœ¼ë¡œ í•  ìˆ˜ ìˆëŠ” ê²ƒì€?",
    "ê±´ê°•í•œ ì•„ì¹¨ ì‹ì‚¬ ì¶”ì²œí•´ì¤˜",
    "ì¬ë¯¸ìˆëŠ” ë†ë‹´ í•˜ë‚˜ í•´ì¤˜"
]

# ê° ì—´ì— ë²„íŠ¼ ë°°ì¹˜
with col1:
    if st.button(suggested_questions[0], use_container_width=True):
        st.session_state.selected_question = suggested_questions[0]

with col2:
    if st.button(suggested_questions[1], use_container_width=True):
        st.session_state.selected_question = suggested_questions[1]

with col3:
    if st.button(suggested_questions[2], use_container_width=True):
        st.session_state.selected_question = suggested_questions[2]

with col4:
    if st.button(suggested_questions[3], use_container_width=True):
        st.session_state.selected_question = suggested_questions[3]

st.divider()

# ëŒ€í™” ë‚´ìš© í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if "selected_question" in st.session_state:
    user_input = st.session_state.selected_question
    del st.session_state.selected_question
else:
    user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")

# ì‚¬ìš©ìê°€ ë©”ì‹œì§€ë¥¼ ì…ë ¥í–ˆì„ ë•Œ
if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": user_input})

    # ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ
    with st.chat_message("user"):
        st.write(user_input)

    # AI ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
    with st.chat_message("assistant"):
        message_placeholder = st.empty()

        with st.spinner("ìƒê° ì¤‘..."):
            try:
                # Gemini ëŒ€í™” ê¸°ë¡ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì—­í•  ì´ë¦„ ìˆ˜ì •)
                gemini_history = []
                for m in st.session_state.messages[:-1]:  # ë§ˆì§€ë§‰ ë©”ì‹œì§€(í˜„ì¬ ì…ë ¥) ì œì™¸
                    role = "model" if m["role"] == "assistant" else "user"
                    gemini_history.append({
                        "role": role,
                        "parts": [m["content"]]
                    })

                # ëª¨ë¸ ìƒì„± ë° ì±„íŒ… ì‹œì‘
                generation_config = genai.types.GenerationConfig(
                    temperature=temperature
                )
                model = genai.GenerativeModel(
                    model_option,
                    generation_config=generation_config
                )
                chat = model.start_chat(history=gemini_history)

                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°›ê¸°
                response = chat.send_message(user_input, stream=True)

                full_response = ""
                for chunk in response:
                    if chunk.text:
                        full_response += chunk.text
                        message_placeholder.write(full_response + "â–Œ")

                message_placeholder.write(full_response)

            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                full_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                message_placeholder.write(full_response)

    # AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    st.session_state.messages.append({"role": "assistant", "content": full_response})

    # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
    st.rerun()

# í•˜ë‹¨ ì•ˆë‚´ ë©”ì‹œì§€
if len(st.session_state.messages) == 0:
    st.info("ğŸ‘† ìœ„ì˜ ì¶”ì²œ ì§ˆë¬¸ì„ í´ë¦­í•˜ê±°ë‚˜, ì•„ë˜ì— ì§ì ‘ ì§ˆë¬¸ì„ ì…ë ¥í•´ë³´ì„¸ìš”!")